"""
Generated By: Cursor (Claude Sonnet 4.5)

Main entry point for calibration master generation.
"""

import argparse
import logging
import subprocess
import sys
import threading
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import ap_common
from ap_common.constants import (
    DEFAULT_FITS_PATTERN,
    HEADER_IMAGETYP,
    TYPE_MASTER_BIAS,
    TYPE_MASTER_DARK,
    TYPE_MASTER_FLAT,
)
from ap_common.fits import update_xisf_headers
from ap_common.logging_config import setup_logging
from ap_common.progress import ProgressTracker

from . import config
from .grouping import group_files, get_group_metadata
from .master_matching import find_matching_master_for_flat
from .script_generator import generate_combined_script, generate_master_filename

logger = logging.getLogger(__name__)

EXIT_SUCCESS = 0
EXIT_ERROR = 1

POLLING_FREQUENCY_SECONDS = 1

# Set default description width for aligned progress bars
# Aligns: "Loading metadata", "Enriching metadata",
# "Calibrating flats", "Creating masters"
ProgressTracker.set_default_desc_width(20)


def get_expected_output_files(
    master_dir: Path,
    calibrated_base_dir: Path,
    bias_groups: List[Tuple[Dict[str, Any], List[str]]],
    dark_groups: List[Tuple[Dict[str, Any], List[str]]],
    flat_groups: List[Tuple[Dict[str, Any], List[str], Optional[str], Optional[str]]],
) -> Tuple[List[Path], List[Path]]:
    """
    Build lists of expected output files for progress monitoring.

    Args:
        master_dir: Directory where master files will be created
        calibrated_base_dir: Base directory for calibrated files
        bias_groups: List of (metadata, file_paths) for bias groups
        dark_groups: List of (metadata, file_paths) for dark groups
        flat_groups: List of (metadata, file_paths, master_bias,
            master_dark) for flat groups

    Returns:
        Tuple of (calibrated_files, master_files):
        - calibrated_files: List of calibrated flat file paths (Phase 1)
        - master_files: List of master file paths (Phase 2)
    """
    calibrated_files = []
    master_files = []

    # Phase 1: Calibrated flat files (if using masters)
    for metadata, file_paths, master_bias, master_dark in flat_groups:
        if master_bias or master_dark:
            master_name = generate_master_filename(metadata, "flat")
            calibrated_dir = calibrated_base_dir / "calibrated" / master_name
            for file_path in file_paths:
                file_stem = Path(file_path).stem
                calibrated_files.append(calibrated_dir / f"{file_stem}_c.xisf")

    # Phase 2: Master files (bias, dark, flat)
    for metadata, _ in bias_groups:
        master_name = generate_master_filename(metadata, "bias")
        master_files.append(master_dir / f"{master_name}.xisf")

    for metadata, _ in dark_groups:
        master_name = generate_master_filename(metadata, "dark")
        master_files.append(master_dir / f"{master_name}.xisf")

    for metadata, _, _, _ in flat_groups:
        master_name = generate_master_filename(metadata, "flat")
        master_files.append(master_dir / f"{master_name}.xisf")

    return calibrated_files, master_files


def monitor_pixinsight_progress_two_phase(
    calibrated_files: List[Path],
    master_files: List[Path],
    stop_event: threading.Event,
    quiet: bool = False,
) -> None:
    """
    Monitor PixInsight progress by polling for expected output files in two phases.

    Phase 1: Monitor calibrated files (if any)
    Phase 2: Monitor master files

    Args:
        calibrated_files: List of expected calibrated file paths (Phase 1)
        master_files: List of expected master file paths (Phase 2)
        stop_event: Event to signal monitoring should stop
        quiet: Suppress progress output
    """
    # Phase 1: Calibration
    if calibrated_files:
        found_files = set()
        tracker = ProgressTracker(
            total=len(calibrated_files),
            desc="Calibrating flats",
            unit="files",
            enabled=not quiet,
        )
        tracker.start()

        while not stop_event.is_set():
            # Check for new calibrated files
            for file_path in calibrated_files:
                if file_path not in found_files and file_path.exists():
                    found_files.add(file_path)
                    tracker.update(n=1)  # No status to avoid showing long filenames

            # All calibration done, move to next phase
            if len(found_files) >= len(calibrated_files):
                break

            time.sleep(POLLING_FREQUENCY_SECONDS)

        # Final update to ensure 100%
        if len(found_files) < len(calibrated_files):
            tracker.update(n=len(calibrated_files) - len(found_files))

        tracker.finish()

    # Phase 2: Master creation
    if master_files:
        found_files = set()
        tracker = ProgressTracker(
            total=len(master_files),
            desc="Creating masters",
            unit="files",
            enabled=not quiet,
        )
        tracker.start()

        while not stop_event.is_set():
            # Check for new master files
            for file_path in master_files:
                if file_path not in found_files and file_path.exists():
                    found_files.add(file_path)
                    tracker.update(n=1)  # No status to keep output clean

            # All masters done
            if len(found_files) >= len(master_files):
                break

            time.sleep(POLLING_FREQUENCY_SECONDS)

        # Final update to ensure 100%
        if len(found_files) < len(master_files):
            tracker.update(n=len(master_files) - len(found_files))

        tracker.finish()


def write_master_imagetyp_headers(master_files: List[Tuple[str, str]]) -> None:
    """
    Write IMAGETYP headers to generated master XISF files.

    PixInsight generates masters with inconsistent IMAGETYP values:
    - Bias masters: "BIAS" (missing "MASTER" prefix)
    - Dark masters: "DARK" (missing "MASTER" prefix)
    - Flat masters: "MASTER FLAT" (has prefix)

    This function adds the "MASTER" prefix to all frame types for consistency.

    Args:
        master_files: List of (master_file_path, frame_type) tuples
                     frame_type is "bias", "dark", or "flat"
    """
    type_mapping = {
        "bias": TYPE_MASTER_BIAS,
        "dark": TYPE_MASTER_DARK,
        "flat": TYPE_MASTER_FLAT,
    }

    for master_file, frame_type in master_files:
        master_path = Path(master_file)
        if not master_path.exists():
            logger.warning(
                f"Master file not found, skipping header update: {master_file}"
            )
            continue

        imagetyp_value = type_mapping.get(frame_type)
        if not imagetyp_value:
            logger.warning(f"Unknown frame type '{frame_type}' for {master_file}")
            continue

        try:
            # Get denormalized header name (should be "IMAGETYP")
            header_key = ap_common.denormalize_header(config.NORMALIZED_HEADER_TYPE)
            if not header_key:
                header_key = HEADER_IMAGETYP  # Fallback

            # Update IMAGETYP header using ap-common
            update_xisf_headers(
                str(master_path),
                {header_key: imagetyp_value},
                comments={header_key: "Master calibration frame type"},
                check_existing=False,  # Always write for newly created files
            )

            logger.debug(f"Updated {master_path.name}: {header_key} = {imagetyp_value}")

        except Exception as e:
            logger.warning(f"Failed to update IMAGETYP header for {master_file}: {e}")


def generate_masters(
    input_dir: str,
    output_dir: str,
    bias_master_dir: Optional[str] = None,
    dark_master_dir: Optional[str] = None,
    script_output_dir: Optional[str] = None,
    timestamp: Optional[str] = None,
    debug: bool = False,
    dryrun: bool = False,
    quiet: bool = False,
) -> Tuple[List[str], List[Tuple[str, str]]]:
    """
    Generate calibration masters from input directory.

    Args:
        input_dir: Directory containing calibration frames
        output_dir: Base output directory
        bias_master_dir: Directory containing bias masters (for flat calibration)
        dark_master_dir: Directory containing dark masters (for flat calibration)
        script_output_dir: Directory for generated JS scripts (default: output_dir/logs)
        timestamp: Timestamp string for script filename (default: current time)
        debug: Enable debug output
        dryrun: Show what would be done without writing scripts
        quiet: Suppress progress output

    Returns:
        Tuple of (script_paths, master_files):
        - script_paths: List of generated script file paths
        - master_files: List of (master_file_path, frame_type) tuples
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # Masters go in output_dir/master subdirectory
    master_dir = output_path / "master"
    master_dir.mkdir(parents=True, exist_ok=True)

    # Scripts go in output_dir/logs subdirectory
    if script_output_dir:
        script_dir = Path(script_output_dir)
    else:
        script_dir = output_path / "logs"
    script_dir.mkdir(parents=True, exist_ok=True)

    # Discover files using ap-common get_filtered_metadata
    logger.info(f"Discovering calibration files in: {input_dir}")

    # Get files for each type using get_filtered_metadata
    files_by_type = {}
    for frame_type in ["bias", "dark", "flat"]:
        try:
            metadata = ap_common.get_filtered_metadata(
                dirs=[input_dir],
                filters={config.NORMALIZED_HEADER_TYPE: frame_type.upper()},
                profileFromPath=False,
                patterns=[DEFAULT_FITS_PATTERN],
                recursive=True,
                required_properties=config.REQUIRED_KEYWORDS[frame_type],
                debug=debug,
                printStatus=not quiet,
            )
            # Convert to list format expected by group_files
            files_by_type[frame_type] = [
                {"path": filename, "headers": headers}
                for filename, headers in metadata.items()
            ]
        except Exception as e:
            logger.warning(f"Failed to discover {frame_type} files: {e}")
            files_by_type[frame_type] = []

    logger.debug(
        f"Found files: Bias: {len(files_by_type['bias'])}, "
        f"Dark: {len(files_by_type['dark'])}, "
        f"Flat: {len(files_by_type['flat'])}"
    )

    # Collect all groups for combined script
    bias_groups_list = []
    dark_groups_list = []
    flat_groups_list = []

    # Track master files for header updates
    master_files_list: List[Tuple[str, str]] = []

    # Process bias frames
    if files_by_type["bias"]:
        bias_groups = group_files(files_by_type["bias"], "bias")

        for group_key, group_files_list in bias_groups.items():
            metadata = get_group_metadata(group_files_list[0]["headers"], "bias")
            file_paths = [f["path"] for f in group_files_list]
            master_name = generate_master_filename(metadata, "bias")

            if len(file_paths) < config.MIN_IMAGES_FOR_INTEGRATION:
                logger.warning(
                    f"Skipping bias group {master_name}: "
                    f"has {len(file_paths)} image(s), "
                    f"need at least {config.MIN_IMAGES_FOR_INTEGRATION}"
                )
                continue

            bias_groups_list.append((metadata, file_paths))

            # Track master file for header updates
            master_file_path = str(master_dir / f"{master_name}.xisf")
            master_files_list.append((master_file_path, "bias"))

            logger.debug(f"Bias group: {len(file_paths)} files -> {master_name}")

        logger.debug(f"\nProcessing {len(bias_groups_list)} bias group(s)")

    # Process dark frames
    if files_by_type["dark"]:
        dark_groups = group_files(files_by_type["dark"], "dark")

        for group_key, group_files_list in dark_groups.items():
            metadata = get_group_metadata(group_files_list[0]["headers"], "dark")
            file_paths = [f["path"] for f in group_files_list]
            master_name = generate_master_filename(metadata, "dark")

            if len(file_paths) < config.MIN_IMAGES_FOR_INTEGRATION:
                logger.warning(
                    f"Skipping dark group {master_name}: "
                    f"has {len(file_paths)} image(s), "
                    f"need at least {config.MIN_IMAGES_FOR_INTEGRATION}"
                )
                continue

            dark_groups_list.append((metadata, file_paths))

            # Track master file for header updates
            master_file_path = str(master_dir / f"{master_name}.xisf")
            master_files_list.append((master_file_path, "dark"))

            logger.debug(f"Dark group: {len(file_paths)} files -> {master_name}")

        logger.debug(f"\nProcessing {len(dark_groups_list)} dark group(s)")

    # Process flat frames
    if files_by_type["flat"]:
        flat_groups = group_files(files_by_type["flat"], "flat")
        n_calibrated = 0

        for group_key, group_files_list in flat_groups.items():
            first_file = group_files_list[0]
            metadata = get_group_metadata(first_file["headers"], "flat")
            file_paths = [f["path"] for f in group_files_list]
            master_name = generate_master_filename(metadata, "flat")

            if len(file_paths) < config.MIN_IMAGES_FOR_INTEGRATION:
                logger.warning(
                    f"Skipping flat group {master_name}: "
                    f"has {len(file_paths)} image(s), "
                    f"need at least {config.MIN_IMAGES_FOR_INTEGRATION}"
                )
                continue

            # Find matching masters
            master_bias_xisf = None
            master_dark_xisf = None

            # Extract exposure times from all flats in group for dark matching
            flat_exposure_times = []
            for file_info in group_files_list:
                headers = file_info["headers"]
                exposure = headers.get(config.NORMALIZED_HEADER_EXPOSURESECONDS)
                if exposure is not None:
                    try:
                        flat_exposure_times.append(float(exposure))
                    except (ValueError, TypeError):
                        pass

            if bias_master_dir:
                master_bias_xisf = find_matching_master_for_flat(
                    bias_master_dir, first_file["headers"], "bias"
                )

            if dark_master_dir:
                master_dark_xisf = find_matching_master_for_flat(
                    dark_master_dir,
                    first_file["headers"],
                    "dark",
                    flat_exposure_times if flat_exposure_times else None,
                )

            flat_groups_list.append(
                (metadata, file_paths, master_bias_xisf, master_dark_xisf)
            )

            # Track master file for header updates
            master_file_path = str(master_dir / f"{master_name}.xisf")
            master_files_list.append((master_file_path, "flat"))

            # Count calibrated groups
            if master_bias_xisf or master_dark_xisf:
                n_calibrated += 1

            # Log details at debug level
            logger.debug(f"Flat group: {len(file_paths)} files -> {master_name}")
            if master_bias_xisf:
                logger.debug(f"  Using bias master: {Path(master_bias_xisf).name}")
            if master_dark_xisf:
                logger.debug(f"  Using dark master: {Path(master_dark_xisf).name}")

        if not quiet:
            if n_calibrated > 0:
                logger.debug(
                    f"\nProcessing {len(flat_groups_list)} "
                    f"flat group(s) ({n_calibrated} "
                    f"with calibration)"
                )
            else:
                logger.debug(f"\nProcessing {len(flat_groups_list)} flat group(s)")

    # Generate single combined script
    if bias_groups_list or dark_groups_list or flat_groups_list:
        if dryrun:
            print("\n[DRYRUN] Would generate combined script...")

        # Create calibrated directories for flat groups (if using masters)
        if flat_groups_list and not dryrun:
            for (
                metadata,
                file_paths,
                master_bias_xisf,
                master_dark_xisf,
            ) in flat_groups_list:
                if master_bias_xisf or master_dark_xisf:
                    # Only create calibrated directory if we're actually calibrating
                    master_name = generate_master_filename(metadata, "flat")
                    calibrated_dir = output_path / "calibrated" / master_name
                    calibrated_dir.mkdir(parents=True, exist_ok=True)

        # Use timestamp for script filename (will match log timestamp)
        if not timestamp:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Define log file path (same directory, same timestamp)
        log_file_path = script_dir / f"{timestamp}.log"
        script_path = script_dir / f"{timestamp}_calibrate_masters.js"

        if dryrun:
            print(f"[DRYRUN] Would write script to: {script_path}")
            print(f"[DRYRUN] Would log to: {log_file_path}")
            print(
                f"[DRYRUN] Summary: "
                f"{len(bias_groups_list)} bias, "
                f"{len(dark_groups_list)} dark, "
                f"{len(flat_groups_list)} flat groups"
            )
            return ([], master_files_list)
        else:
            combined_script = generate_combined_script(
                str(master_dir),
                bias_groups_list,
                dark_groups_list,
                flat_groups_list,
                str(log_file_path),
                str(output_path),  # calibrated_base_dir
            )

            script_path.write_text(combined_script, encoding="utf-8")
            logger.debug(
                f"Generated script: {script_path.name}, "
                f"console_log: {log_file_path.name}"
            )
            return ([str(script_path)], master_files_list)

    return ([], [])


def run_pixinsight(
    pixinsight_binary: str,
    script_path: str,
    calibrated_files: List[Path],
    master_files: List[Path],
    instance_id: int = 123,
    force_exit: bool = True,
    quiet: bool = False,
    debug: bool = False,
) -> int:
    """
    Execute PixInsight with the generated script.

    Args:
        pixinsight_binary: Path to PixInsight binary/executable
        script_path: Path to the JavaScript script to execute
        calibrated_files: List of expected calibrated files (Phase 1)
        master_files: List of expected master files (Phase 2)
        instance_id: PixInsight instance ID (default: 123)
        force_exit: Exit PixInsight after script completes (default: True)
        quiet: Suppress progress output
        debug: Show debug output including PixInsight stderr

    Returns:
        Exit code from PixInsight process
    """
    script_path_obj = Path(script_path).resolve()
    pixinsight_binary_obj = Path(pixinsight_binary).resolve()

    if not pixinsight_binary_obj.exists():
        raise FileNotFoundError(f"PixInsight binary not found: {pixinsight_binary_obj}")

    if not script_path_obj.exists():
        raise FileNotFoundError(f"Script not found: {script_path_obj}")

    # Extract log file path from script directory
    log_file = (
        script_path_obj.parent
        / f"{script_path_obj.stem.replace('_calibrate_masters', '')}.log"
    )

    logger.debug(
        f"Executing PixInsight: "
        f"binary={pixinsight_binary_obj}, "
        f"script={script_path_obj}, "
        f"console_log={log_file}, "
        f"instance_id={instance_id}, "
        f"automation_mode=enabled"
    )

    # Build command: PixInsight --automation-mode
    # -n=<instance_id> -r=<script_path> --force-exit
    # Note: PixInsight requires equals sign format, not space-separated arguments
    # --automation-mode prevents interactive dialogs and GUI messages
    cmd = [
        str(pixinsight_binary_obj),
        "--automation-mode",
        f"-n={instance_id}",
        f"-r={script_path_obj}",
    ]

    if force_exit:
        cmd.append("--force-exit")
        logger.debug("Force exit: enabled")

    logger.debug(f"Running: {' '.join(cmd)}")

    # Start two-phase progress monitoring in background thread
    stop_event = threading.Event()
    monitor_thread = threading.Thread(
        target=monitor_pixinsight_progress_two_phase,
        args=(calibrated_files, master_files, stop_event, quiet),
        daemon=True,
    )
    monitor_thread.start()

    # Execute and wait for completion
    # Console output is logged by PixInsight via
    # Console.beginLog() in the script
    try:
        result = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL if not debug else subprocess.STDOUT,
            check=False,
            text=True,
        )

        # Log any stderr/stdout from the process itself
        # (e.g., GPU warnings) in debug mode
        if result.stdout and debug:
            logger.debug(result.stdout)

        return result.returncode
    except Exception as e:
        logger.error(f"Failed to execute PixInsight: {e}")
        raise
    finally:
        stop_event.set()
        monitor_thread.join(timeout=5)


def main() -> int:
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Generate calibration master frames using PixInsight"
    )
    parser.add_argument(
        "input_dir",
        help="Input directory containing calibration frames (bias, dark, flat)",
    )
    parser.add_argument(
        "output_dir",
        help="Output directory for master calibration frames",
    )
    parser.add_argument(
        "--bias-master-dir",
        help="Directory containing bias master library (for flat calibration)",
    )
    parser.add_argument(
        "--dark-master-dir",
        help="Directory containing dark master library (for flat calibration)",
    )
    parser.add_argument(
        "--script-dir",
        help=(
            "Directory for generated PixInsight scripts"
            " and logs (default: output_dir/logs)"
        ),
    )
    parser.add_argument(
        "--pixinsight-binary",
        help="Path to PixInsight binary (required for execution)",
    )
    parser.add_argument(
        "--instance-id",
        type=int,
        default=123,
        help="PixInsight instance ID (default: 123)",
    )
    parser.add_argument(
        "--no-force-exit",
        action="store_true",
        help=(
            "Don't exit PixInsight after script"
            " completes (default: exit automatically)"
        ),
    )
    parser.add_argument(
        "--script-only",
        action="store_true",
        help="Generate scripts only, do not execute PixInsight",
    )
    parser.add_argument(
        "--dryrun",
        action="store_true",
        help="Show what would be done without writing scripts or executing PixInsight",
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug output",
    )
    parser.add_argument(
        "--quiet",
        "-q",
        action="store_true",
        help="Suppress progress output",
    )

    args = parser.parse_args()

    # Setup logging
    logger = setup_logging(name="ap_create_master", debug=args.debug, quiet=args.quiet)

    try:
        # Generate timestamp once to use for both script and log
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        scripts, master_files = generate_masters(
            args.input_dir,
            args.output_dir,
            args.bias_master_dir,
            args.dark_master_dir,
            args.script_dir,
            timestamp,
            debug=args.debug,
            dryrun=args.dryrun,
            quiet=args.quiet,
        )

        if args.dryrun:
            # Dryrun mode: no scripts were written
            print("\n[DRYRUN] Completed. No scripts written, no execution performed.")
        elif scripts:
            if not args.quiet:
                print(f"\nGenerated script: {Path(scripts[0]).name}")

            # Execute PixInsight if requested
            if not args.script_only:
                if not args.pixinsight_binary:
                    logger.error(
                        "--pixinsight-binary is required to execute PixInsight"
                    )
                    print(
                        "ERROR: --pixinsight-binary is required to execute PixInsight"
                    )
                    print("Use --script-only or --dryrun to skip execution")
                    return EXIT_ERROR

                # Calculate expected output files for progress monitoring
                # Re-run group generation to get the lists we need
                output_path = Path(args.output_dir)
                master_dir = output_path / "master"

                # Get files by type (same as in generate_masters)
                files_by_type = {}
                for frame_type in ["bias", "dark", "flat"]:
                    try:
                        metadata = ap_common.get_filtered_metadata(
                            dirs=[args.input_dir],
                            filters={config.NORMALIZED_HEADER_TYPE: frame_type.upper()},
                            profileFromPath=False,
                            patterns=[DEFAULT_FITS_PATTERN],
                            recursive=True,
                            required_properties=config.REQUIRED_KEYWORDS[frame_type],
                            debug=False,
                            printStatus=False,
                        )
                        files_by_type[frame_type] = [
                            {"path": filename, "headers": headers}
                            for filename, headers in metadata.items()
                        ]
                    except Exception:
                        files_by_type[frame_type] = []

                # Build group lists to calculate expected files
                from .grouping import group_files, get_group_metadata
                from .master_matching import find_matching_master_for_flat

                bias_groups_list = []
                dark_groups_list = []
                flat_groups_list = []

                if files_by_type["bias"]:
                    bias_groups = group_files(files_by_type["bias"], "bias")
                    for _, group_files_list in bias_groups.items():
                        metadata = get_group_metadata(
                            group_files_list[0]["headers"], "bias"
                        )
                        file_paths = [f["path"] for f in group_files_list]
                        if len(file_paths) < config.MIN_IMAGES_FOR_INTEGRATION:
                            continue
                        bias_groups_list.append((metadata, file_paths))

                if files_by_type["dark"]:
                    dark_groups = group_files(files_by_type["dark"], "dark")
                    for _, group_files_list in dark_groups.items():
                        metadata = get_group_metadata(
                            group_files_list[0]["headers"], "dark"
                        )
                        file_paths = [f["path"] for f in group_files_list]
                        if len(file_paths) < config.MIN_IMAGES_FOR_INTEGRATION:
                            continue
                        dark_groups_list.append((metadata, file_paths))

                if files_by_type["flat"]:
                    flat_groups = group_files(files_by_type["flat"], "flat")
                    for _, group_files_list in flat_groups.items():
                        first_file = group_files_list[0]
                        metadata = get_group_metadata(first_file["headers"], "flat")
                        file_paths = [f["path"] for f in group_files_list]
                        if len(file_paths) < config.MIN_IMAGES_FOR_INTEGRATION:
                            continue

                        master_bias_xisf = None
                        master_dark_xisf = None

                        flat_exposure_times = []
                        for file_info in group_files_list:
                            headers = file_info["headers"]
                            exposure = headers.get(
                                config.NORMALIZED_HEADER_EXPOSURESECONDS
                            )
                            if exposure is not None:
                                try:
                                    flat_exposure_times.append(float(exposure))
                                except (ValueError, TypeError):
                                    pass

                        if args.bias_master_dir:
                            master_bias_xisf = find_matching_master_for_flat(
                                args.bias_master_dir, first_file["headers"], "bias"
                            )

                        if args.dark_master_dir:
                            master_dark_xisf = find_matching_master_for_flat(
                                args.dark_master_dir,
                                first_file["headers"],
                                "dark",
                                flat_exposure_times if flat_exposure_times else None,
                            )

                        flat_groups_list.append(
                            (metadata, file_paths, master_bias_xisf, master_dark_xisf)
                        )

                calibrated_files, master_files_list = get_expected_output_files(
                    master_dir,
                    output_path,
                    bias_groups_list,
                    dark_groups_list,
                    flat_groups_list,
                )

                exit_code = run_pixinsight(
                    args.pixinsight_binary,
                    scripts[0],
                    calibrated_files,
                    master_files_list,
                    args.instance_id,
                    not args.no_force_exit,
                    args.quiet,
                    args.debug,
                )

                if exit_code == 0:
                    if not args.quiet:
                        print("\nPixInsight execution completed successfully!")

                    # Write IMAGETYP headers to generated master files
                    if master_files:
                        logger.debug("Writing IMAGETYP headers to master files...")
                        write_master_imagetyp_headers(master_files)
                        if not args.quiet:
                            print(f"Updated {len(master_files)} master file(s)")

                    if not args.quiet:
                        print(f"Master files: {args.output_dir}/master")
                        print(f"Logs: {args.output_dir}/logs")
                else:
                    logger.warning(f"PixInsight exited with code {exit_code}")
                    print(f"WARNING: PixInsight exited with code {exit_code}")
                    return exit_code
            else:
                print("Script-only mode: PixInsight execution skipped")
                binary = args.pixinsight_binary or "<pixinsight-binary>"
                print(
                    f"To execute: {binary}"
                    f" --automation-mode"
                    f" -n={args.instance_id}"
                    f" -r={scripts[0]}"
                    f" --force-exit"
                )
        else:
            print("No calibration frames found to process.")

        return EXIT_SUCCESS
    except Exception as e:
        logger.error(f"Error: {e}")
        print(f"ERROR: {e}", file=sys.stderr)
        import traceback

        traceback.print_exc()
        return EXIT_ERROR


if __name__ == "__main__":
    sys.exit(main())
