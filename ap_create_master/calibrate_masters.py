"""
Generated By: Cursor (Claude Sonnet 4.5)

Main entry point for calibration master generation.
"""

import argparse
import logging
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

import ap_common
from ap_common.logging_config import setup_logging
from ap_common.progress import progress_iter

from . import config
from .grouping import group_files, get_group_metadata
from .master_matching import find_matching_master_for_flat
from .script_generator import generate_combined_script

logger = logging.getLogger("ap_create_master.calibrate_masters")


def generate_masters(
    input_dir: str,
    output_dir: str,
    bias_master_dir: Optional[str] = None,
    dark_master_dir: Optional[str] = None,
    script_output_dir: Optional[str] = None,
    timestamp: Optional[str] = None,
    debug: bool = False,
    dryrun: bool = False,
) -> List[str]:
    """
    Generate calibration masters from input directory.

    Args:
        input_dir: Directory containing calibration frames
        output_dir: Base output directory
        bias_master_dir: Directory containing bias masters (for flat calibration)
        dark_master_dir: Directory containing dark masters (for flat calibration)
        script_output_dir: Directory for generated JS scripts (default: output_dir/logs)
        timestamp: Timestamp string for script filename (default: current time)
        debug: Enable debug output
        dryrun: Show what would be done without writing scripts

    Returns:
        List of generated script file paths
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # Masters go in output_dir/master subdirectory
    master_dir = output_path / "master"
    master_dir.mkdir(parents=True, exist_ok=True)

    # Scripts go in output_dir/logs subdirectory
    if script_output_dir:
        script_dir = Path(script_output_dir)
    else:
        script_dir = output_path / "logs"
    script_dir.mkdir(parents=True, exist_ok=True)

    # Discover files using ap-common get_filtered_metadata
    print(f"Discovering calibration files in: {input_dir}")

    # Get files for each type using get_filtered_metadata
    files_by_type = {}
    for frame_type in ["bias", "dark", "flat"]:
        try:
            metadata = ap_common.get_filtered_metadata(
                dirs=[input_dir],
                filters={config.NORMALIZED_HEADER_TYPE: frame_type.upper()},
                profileFromPath=False,
                patterns=[r".*\.fits$", r".*\.fit$"],
                recursive=True,
                required_properties=config.REQUIRED_KEYWORDS[frame_type],
                debug=False,
                printStatus=False,
            )
            # Convert to list format expected by group_files
            files_by_type[frame_type] = [
                {"path": filename, "headers": headers}
                for filename, headers in metadata.items()
            ]
        except Exception as e:
            print(f"Warning: Failed to discover {frame_type} files: {e}")
            files_by_type[frame_type] = []

    print("Found files:")
    print(f"  Bias: {len(files_by_type['bias'])}")
    print(f"  Dark: {len(files_by_type['dark'])}")
    print(f"  Flat: {len(files_by_type['flat'])}")

    # Collect all groups for combined script
    bias_groups_list = []
    dark_groups_list = []
    flat_groups_list = []

    # Process bias frames
    if files_by_type["bias"]:
        print("\nProcessing bias frames...")
        bias_groups = group_files(files_by_type["bias"], "bias")

        for group_key, group_files_list in bias_groups.items():
            metadata = get_group_metadata(group_files_list[0]["headers"], "bias")
            file_paths = [f["path"] for f in group_files_list]
            bias_groups_list.append((metadata, file_paths))
            print(f"  Group: {len(file_paths)} files")

    # Process dark frames
    if files_by_type["dark"]:
        print("\nProcessing dark frames...")
        dark_groups = group_files(files_by_type["dark"], "dark")

        for group_key, group_files_list in dark_groups.items():
            metadata = get_group_metadata(group_files_list[0]["headers"], "dark")
            file_paths = [f["path"] for f in group_files_list]
            dark_groups_list.append((metadata, file_paths))
            print(f"  Group: {len(file_paths)} files")

    # Process flat frames
    if files_by_type["flat"]:
        print("\nProcessing flat frames...")
        flat_groups = group_files(files_by_type["flat"], "flat")

        for group_key, group_files_list in flat_groups.items():
            first_file = group_files_list[0]
            metadata = get_group_metadata(first_file["headers"], "flat")
            file_paths = [f["path"] for f in group_files_list]

            # Find matching masters
            master_bias_xisf = None
            master_dark_xisf = None

            # Extract exposure times from all flats in group for dark matching
            flat_exposure_times = []
            for file_info in group_files_list:
                headers = file_info["headers"]
                exposure = headers.get(config.NORMALIZED_HEADER_EXPOSURESECONDS)
                if exposure is not None:
                    try:
                        flat_exposure_times.append(float(exposure))
                    except (ValueError, TypeError):
                        pass

            if bias_master_dir:
                logger.debug("Looking for bias master for group...")
                master_bias_xisf = find_matching_master_for_flat(
                    bias_master_dir, first_file["headers"], "bias"
                )

            if dark_master_dir:
                logger.debug("Looking for dark master for group...")
                master_dark_xisf = find_matching_master_for_flat(
                    dark_master_dir,
                    first_file["headers"],
                    "dark",
                    flat_exposure_times if flat_exposure_times else None,
                )

            flat_groups_list.append(
                (metadata, file_paths, master_bias_xisf, master_dark_xisf)
            )
            print(f"  Group: {len(file_paths)} files")
            if master_bias_xisf:
                print(f"    Using bias master: {Path(master_bias_xisf).name}")
            if master_dark_xisf:
                print(f"    Using dark master: {Path(master_dark_xisf).name}")

    # Generate single combined script
    if bias_groups_list or dark_groups_list or flat_groups_list:
        if dryrun:
            print("\n[DRYRUN] Would generate combined script...")
        else:
            print("\nGenerating combined script...")

        # Create calibrated directories for flat groups (if using masters)
        if flat_groups_list and not dryrun:
            for (
                metadata,
                file_paths,
                master_bias_xisf,
                master_dark_xisf,
            ) in flat_groups_list:
                if master_bias_xisf or master_dark_xisf:
                    # Only create calibrated directory if we're actually calibrating
                    from .script_generator import generate_master_filename

                    master_name = generate_master_filename(metadata, "flat")
                    calibrated_dir = output_path / "calibrated" / master_name
                    calibrated_dir.mkdir(parents=True, exist_ok=True)

        # Use timestamp for script filename (will match log timestamp)
        if not timestamp:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Define log file path (same directory, same timestamp)
        log_file_path = script_dir / f"{timestamp}.log"
        script_path = script_dir / f"{timestamp}_calibrate_masters.js"

        if dryrun:
            print(f"[DRYRUN] Would write script to: {script_path}")
            print(f"[DRYRUN] Would log to: {log_file_path}")
            print(
                f"[DRYRUN] Summary: {len(bias_groups_list)} bias, {len(dark_groups_list)} dark, {len(flat_groups_list)} flat groups"
            )
            return []
        else:
            combined_script = generate_combined_script(
                str(master_dir),
                bias_groups_list,
                dark_groups_list,
                flat_groups_list,
                str(log_file_path),
                str(output_path),  # calibrated_base_dir
            )

            script_path.write_text(combined_script, encoding="utf-8")
            logger.info(
                f"Generated script: {script_path.name}, console_log: {log_file_path.name}"
            )
            return [str(script_path)]

    return []


def run_pixinsight(
    pixinsight_binary: str,
    script_path: str,
    instance_id: int = 123,
    force_exit: bool = True,
) -> int:
    """
    Execute PixInsight with the generated script.

    Args:
        pixinsight_binary: Path to PixInsight binary/executable
        script_path: Path to the JavaScript script to execute
        instance_id: PixInsight instance ID (default: 123)
        force_exit: Exit PixInsight after script completes (default: True)

    Returns:
        Exit code from PixInsight process
    """
    script_path_obj = Path(script_path).resolve()
    pixinsight_binary_obj = Path(pixinsight_binary).resolve()

    if not pixinsight_binary_obj.exists():
        raise FileNotFoundError(f"PixInsight binary not found: {pixinsight_binary_obj}")

    if not script_path_obj.exists():
        raise FileNotFoundError(f"Script not found: {script_path_obj}")

    # Extract log file path from script directory
    log_file = (
        script_path_obj.parent
        / f"{script_path_obj.stem.replace('_calibrate_masters', '')}.log"
    )

    logger.info(
        f"Executing PixInsight: binary={pixinsight_binary_obj}, script={script_path_obj}, "
        f"console_log={log_file}, instance_id={instance_id}, automation_mode=enabled"
    )

    # Build command: PixInsight --automation-mode -n=<instance_id> -r=<script_path> --force-exit
    # Note: PixInsight requires equals sign format, not space-separated arguments
    # --automation-mode prevents interactive dialogs and GUI messages
    cmd = [
        str(pixinsight_binary_obj),
        "--automation-mode",
        f"-n={instance_id}",
        f"-r={script_path_obj}",
    ]

    if force_exit:
        cmd.append("--force-exit")
        logger.info("Force exit: enabled")

    logger.info(f"Running: {' '.join(cmd)}")

    # Execute and wait for completion
    # Console output is logged by PixInsight via Console.beginLog() in the script
    try:
        result = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            check=False,
            text=True,
        )

        # Log any stderr/stdout from the process itself (e.g., GPU warnings)
        if result.stdout:
            logger.info(result.stdout)

        return result.returncode
    except Exception as e:
        logger.error(f"Failed to execute PixInsight: {e}")
        raise


def main() -> int:
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Generate calibration master frames using PixInsight"
    )
    parser.add_argument(
        "input_dir",
        help="Input directory containing calibration frames (bias, dark, flat)",
    )
    parser.add_argument(
        "output_dir",
        help="Output directory for master calibration frames",
    )
    parser.add_argument(
        "--bias-master-dir",
        help="Directory containing bias master library (for flat calibration)",
    )
    parser.add_argument(
        "--dark-master-dir",
        help="Directory containing dark master library (for flat calibration)",
    )
    parser.add_argument(
        "--script-dir",
        help="Directory for generated PixInsight scripts and logs (default: output_dir/logs)",
    )
    parser.add_argument(
        "--pixinsight-binary",
        help="Path to PixInsight binary (required for execution)",
    )
    parser.add_argument(
        "--instance-id",
        type=int,
        default=123,
        help="PixInsight instance ID (default: 123)",
    )
    parser.add_argument(
        "--no-force-exit",
        action="store_true",
        help="Don't exit PixInsight after script completes (default: exit automatically)",
    )
    parser.add_argument(
        "--script-only",
        action="store_true",
        help="Generate scripts only, do not execute PixInsight",
    )
    parser.add_argument(
        "--dryrun",
        action="store_true",
        help="Show what would be done without writing scripts or executing PixInsight",
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug output",
    )
    parser.add_argument(
        "--quiet",
        "-q",
        action="store_true",
        help="Suppress progress output",
    )

    args = parser.parse_args()

    # Setup logging
    logger = setup_logging(name="ap_create_master", debug=args.debug)

    try:
        # Generate timestamp once to use for both script and log
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        scripts = generate_masters(
            args.input_dir,
            args.output_dir,
            args.bias_master_dir,
            args.dark_master_dir,
            args.script_dir,
            timestamp,
            debug=args.debug,
            dryrun=args.dryrun,
        )

        if args.dryrun:
            # Dryrun mode: no scripts were written
            print("\n[DRYRUN] Completed. No scripts written, no execution performed.")
        elif scripts:
            print(f"Generated combined script: {Path(scripts[0]).name}")
            print(f"Script location: {Path(scripts[0]).parent}")
            print(f"Masters will be output to: {args.output_dir}")

            # Execute PixInsight if requested
            if not args.script_only:
                if not args.pixinsight_binary:
                    logger.error(
                        "--pixinsight-binary is required to execute PixInsight"
                    )
                    print(
                        "ERROR: --pixinsight-binary is required to execute PixInsight"
                    )
                    print("Use --script-only or --dryrun to skip execution")
                    return 1

                exit_code = run_pixinsight(
                    args.pixinsight_binary,
                    scripts[0],
                    args.instance_id,
                    not args.no_force_exit,
                )

                if exit_code == 0:
                    print("PixInsight execution completed successfully!")
                    print(f"Master files: {args.output_dir}/master")
                    print(f"Logs: {args.output_dir}/logs")
                else:
                    logger.warning(f"PixInsight exited with code {exit_code}")
                    print(f"WARNING: PixInsight exited with code {exit_code}")
                    return exit_code
            else:
                print("Script-only mode: PixInsight execution skipped")
                print(
                    f"To execute: {args.pixinsight_binary or '<pixinsight-binary>'} --automation-mode -n={args.instance_id} -r={scripts[0]} --force-exit"
                )
        else:
            print("No calibration frames found to process.")

        return 0
    except Exception as e:
        logger.error(f"Error: {e}")
        print(f"ERROR: {e}", file=sys.stderr)
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
